# demo_web_search.py - ç½‘ç»œæ£€ç´¢åŠŸèƒ½æ¼”ç¤º

from web_search_integration import DuckDuckGoSearchEngine, WikipediaSearchEngine, HybridRAGSystem
from retriever_enhanced import EnhancedRetriever
import json
import time


def test_web_search_engines():
    """æµ‹è¯•å„ä¸ªæœç´¢å¼•æ“"""
    print("ğŸŒ æµ‹è¯•ç½‘ç»œæœç´¢å¼•æ“")
    print("=" * 60)

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "English present perfect tense",
        "grammar rules articles a an the",
        "English conditionals if clauses"
    ]

    # æµ‹è¯•DuckDuckGo
    print("\nğŸ¦† DuckDuckGo æœç´¢å¼•æ“æµ‹è¯•")
    ddg = DuckDuckGoSearchEngine()

    for query in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        try:
            results = ddg.search(query, max_results=3)
            print(f"ğŸ“Š æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result['title']}")
                print(f"     {result['content'][:80]}...")
                print(f"     æ¥æº: {result['source']}")
        except Exception as e:
            print(f"  âŒ æœç´¢å¤±è´¥: {e}")

    # æµ‹è¯•ç»´åŸºç™¾ç§‘
    print("\nğŸ“š ç»´åŸºç™¾ç§‘æœç´¢å¼•æ“æµ‹è¯•")
    wiki = WikipediaSearchEngine()

    for query in ["present perfect", "english grammar", "conditionals"]:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        try:
            results = wiki.search(query, max_results=2)
            print(f"ğŸ“Š æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result['title']}")
                print(f"     {result['content'][:80]}...")
                print(f"     æ¥æº: {result['source']}")
        except Exception as e:
            print(f"  âŒ æœç´¢å¤±è´¥: {e}")


def test_hybrid_system():
    """æµ‹è¯•æ··åˆRAGç³»ç»Ÿ"""
    print("\n\nğŸ¯ æ··åˆRAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    # åˆå§‹åŒ–æœ¬åœ°æ£€ç´¢å™¨
    try:
        local_retriever = EnhancedRetriever()
        print("âœ… æœ¬åœ°æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æœ¬åœ°æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        local_retriever = None

    # åˆ›å»ºæ··åˆç³»ç»Ÿ
    hybrid_system = HybridRAGSystem(local_retriever, enable_web_search=True)

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "ç°åœ¨å®Œæˆæ—¶çš„ç”¨æ³•",
        "å† è¯çš„ä½¿ç”¨è§„åˆ™",
        "è™šæ‹Ÿè¯­æ°”çš„è¯­æ³•"
    ]

    for query in test_queries:
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        print("-" * 40)

        try:
            start_time = time.time()
            docs = hybrid_system.search_and_retrieve(
                query,
                use_local=local_retriever is not None,
                use_web=True
            )
            search_time = time.time() - start_time

            print(f"â±ï¸  æœç´¢è€—æ—¶: {search_time:.2f}ç§’")
            print(f"ğŸ“Š æ£€ç´¢æ–‡æ¡£æ•°: {len(docs)}")

            # ç»Ÿè®¡æ–‡æ¡£ç±»å‹
            local_docs = [d for d in docs if d.metadata.get("source_type") == "local"]
            web_docs = [d for d in docs if d.metadata.get("source_type") == "web"]

            print(f"ğŸ“š æœ¬åœ°æ–‡æ¡£: {len(local_docs)} ä¸ª")
            print(f"ğŸŒ ç½‘ç»œæ–‡æ¡£: {len(web_docs)} ä¸ª")

            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æ¡£é¢„è§ˆ
            print("\nğŸ“„ æ–‡æ¡£é¢„è§ˆ:")
            for i, doc in enumerate(docs[:3], 1):
                source_type = doc.metadata.get("source_type", "unknown")
                source_label = "æœ¬åœ°" if source_type == "local" else "ç½‘ç»œ"
                title = doc.metadata.get("title", "æ— æ ‡é¢˜")
                content = doc.page_content[:100]

                print(f"  {i}. [{source_label}] {title}")
                print(f"     {content}...")
                print()

        except Exception as e:
            print(f"âŒ æ··åˆæ£€ç´¢å¤±è´¥: {e}")


def test_query_enhancement():
    """æµ‹è¯•æŸ¥è¯¢å¢å¼ºåŠŸèƒ½"""
    print("\n\nğŸ”§ æŸ¥è¯¢å¢å¼ºåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    local_retriever = None  # ä¸ºç®€åŒ–æµ‹è¯•
    hybrid_system = HybridRAGSystem(local_retriever, enable_web_search=True)

    # æµ‹è¯•æŸ¥è¯¢å¢å¼º
    queries = [
        "ç°åœ¨å®Œæˆæ—¶",
        "å† è¯ç”¨æ³•",
        "è™šæ‹Ÿè¯­æ°”",
        "English grammar"  # è‹±æ–‡æŸ¥è¯¢
    ]

    for query in queries:
        enhanced = hybrid_system._enhance_query(query)
        print(f"åŸå§‹: {query}")
        print(f"å¢å¼º: {enhanced}")
        print(f"å˜åŒ–: {'æ˜¯' if query != enhanced else 'å¦'}")
        print()


def save_test_results():
    """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
    print("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")

    # æ”¶é›†æµ‹è¯•æ•°æ®
    test_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "engines_tested": ["DuckDuckGo", "Wikipedia"],
        "features_tested": [
            "ç½‘ç»œæœç´¢",
            "æ··åˆæ£€ç´¢",
            "æŸ¥è¯¢å¢å¼º",
            "æ–‡æ¡£å»é‡",
            "è´¨é‡åˆ†æ"
        ],
        "recommendations": [
            "DuckDuckGo é€‚åˆä¸€èˆ¬æŸ¥è¯¢",
            "ç»´åŸºç™¾ç§‘ é€‚åˆå­¦æœ¯å†…å®¹",
            "æ··åˆæ£€ç´¢ æä¾›æœ€å…¨é¢ä¿¡æ¯",
            "æœ¬åœ°æ£€ç´¢ é€Ÿåº¦å¿«ä¸”å¯é ",
            "ç½‘ç»œæ£€ç´¢ è·å–æœ€æ–°èµ„æ–™"
        ]
    }

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("web_search_test_results.json", "w", encoding="utf-8") as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)

    print("âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° web_search_test_results.json")


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ç½‘ç»œæ£€ç´¢åŠŸèƒ½æ¼”ç¤º")
    print("=" * 80)

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_web_search_engines()
    test_hybrid_system()
    test_query_enhancement()
    save_test_results()

    print("\nğŸ‰ ç½‘ç»œæ£€ç´¢åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    print("ğŸ’¡ æ¥ä¸‹æ¥å¯ä»¥ï¼š")
    print("1. è¿è¡Œ python app_hybrid.py å¯åŠ¨æ··åˆRAGåº”ç”¨")
    print("2. åœ¨Gradioç•Œé¢ä¸­æµ‹è¯•ç½‘ç»œæœç´¢åŠŸèƒ½")
    print("3. æŸ¥çœ‹ç”Ÿæˆçš„ web_search_test_results.json æ–‡ä»¶")