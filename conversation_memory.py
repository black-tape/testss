# conversation_memory.py - ä¸Šä¸‹æ–‡è®°å¿†åŠŸèƒ½æ¨¡å—

from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json
import os


@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡æ•°æ®ç»“æ„"""
    user_query: str
    ai_response: str
    timestamp: datetime
    session_id: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    retrieved_docs: List[str] = field(default_factory=list)
    context_summary: str = ""
    keywords: List[str] = field(default_factory=list)


class ConversationMemory:
    """å¯¹è¯è®°å¿†ç®¡ç†å™¨"""

    def __init__(self,
                 max_history: int = 10,
                 max_context_length: int = 2000,
                 memory_file: str = "conversation_history.json"):
        self.max_history = max_history
        self.max_context_length = max_context_length
        self.memory_file = memory_file
        self.conversation_history: List[ConversationTurn] = []
        self.current_session_id = self._generate_session_id()

        # åŠ è½½å†å²è®°å½•
        self._load_history()

    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return datetime.now().strftime("%Y%m%d_%H%M%S")

    def add_conversation_turn(self,
                            user_query: str,
                            ai_response: str,
                            metadata: Dict[str, Any] = None,
                            retrieved_docs: List[str] = None) -> None:
        """æ·»åŠ æ–°çš„å¯¹è¯è½®æ¬¡"""
        turn = ConversationTurn(
            user_query=user_query,
            ai_response=ai_response,
            timestamp=datetime.now(),
            session_id=self.current_session_id,
            metadata=metadata or {},
            retrieved_docs=retrieved_docs or [],
            keywords=self._extract_keywords(user_query + " " + ai_response),
            context_summary=self._generate_summary(user_query, ai_response)
        )

        self.conversation_history.append(turn)

        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]

        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_history()

    def get_context_for_query(self, current_query: str, max_length: int = None) -> str:
        """ä¸ºå½“å‰æŸ¥è¯¢è·å–ä¸Šä¸‹æ–‡"""
        if not self.conversation_history:
            return ""

        max_length = max_length or self.max_context_length

        # è·å–ç›¸å…³çš„å†å²å¯¹è¯
        relevant_contexts = self._get_relevant_context(current_query)

        # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context_parts = []
        current_length = 0

        for turn in relevant_contexts:
            context_snippet = self._format_context_turn(turn)

            if current_length + len(context_snippet) > max_length:
                break

            context_parts.append(context_snippet)
            current_length += len(context_snippet)

        if not context_parts:
            return ""

        context_header = f"ğŸ“ **å¯¹è¯å†å² (æœ€è¿‘{len(context_parts)}è½®):**\n\n"
        return context_header + "\n\n".join(context_parts)

    def _get_relevant_context(self, current_query: str) -> List[ConversationTurn]:
        """è·å–ä¸å½“å‰æŸ¥è¯¢ç›¸å…³çš„ä¸Šä¸‹æ–‡"""
        if not self.conversation_history:
            return []

        # ç®€å•çš„ç›¸å…³æ€§è®¡ç®—
        current_keywords = set(self._extract_keywords(current_query))

        scored_turns = []
        for turn in self.conversation_history[-5:]:  # åªè€ƒè™‘æœ€è¿‘çš„5è½®å¯¹è¯
            turn_keywords = set(turn.keywords)

            # è®¡ç®—å…³é”®è¯é‡å åº¦
            overlap = len(current_keywords & turn_keywords)
            recency_score = len(self.conversation_history) - self.conversation_history.index(turn)

            total_score = overlap * 2 + recency_score
            scored_turns.append((total_score, turn))

        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›
        scored_turns.sort(key=lambda x: x[0], reverse=True)
        return [turn for _, turn in scored_turns]

    def _format_context_turn(self, turn: ConversationTurn) -> str:
        """æ ¼å¼åŒ–å•ä¸ªå¯¹è¯è½®æ¬¡"""
        time_str = turn.timestamp.strftime("%H:%M")
        return f"**[{time_str}] ç”¨æˆ·:** {turn.user_query}\n**åŠ©æ‰‹:** {turn.ai_response}"

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
        english_grammar_terms = [
            "present perfect", "past tense", "future tense", "conditionals",
            "articles", "prepositions", "conjunctions", "verbs", "nouns",
            "adjectives", "adverbs", "pronouns", "tense", "aspect",
            "grammar", "syntax", "clause", "phrase", "sentence"
        ]

        chinese_grammar_terms = [
            "ç°åœ¨å®Œæˆæ—¶", "è¿‡å»æ—¶", "å°†æ¥æ—¶", "è™šæ‹Ÿè¯­æ°”",
            "å† è¯", "ä»‹è¯", "è¿è¯", "åŠ¨è¯", "åè¯",
            "å½¢å®¹è¯", "å‰¯è¯", "ä»£è¯", "æ—¶æ€", "ä½“æ€",
            "è¯­æ³•", "å¥æ³•", "ä»å¥", "çŸ­è¯­", "å¥å­"
        ]

        text_lower = text.lower()
        keywords = []

        for term in english_grammar_terms + chinese_grammar_terms:
            if term.lower() in text_lower:
                keywords.append(term)

        return list(set(keywords))  # å»é‡

    def _generate_summary(self, user_query: str, ai_response: str) -> str:
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        # ç®€å•çš„æ‘˜è¦ç”Ÿæˆï¼ˆå¯ä»¥æ›¿æ¢ä¸ºLLMç”Ÿæˆï¼‰
        return f"ç”¨æˆ·è¯¢é—®äº†å…³äº{self._extract_main_topic(user_query)}çš„é—®é¢˜"

    def _extract_main_topic(self, text: str) -> str:
        """æå–ä¸»è¦ä¸»é¢˜"""
        topics = ["æ—¶æ€", "è¯­æ³•", "å† è¯", "è™šæ‹Ÿè¯­æ°”", "æ¡ä»¶å¥", "ä»å¥"]
        text_lower = text.lower()

        for topic in topics:
            if topic in text_lower:
                return topic

        return "è‹±è¯­è¯­æ³•"

    def _save_history(self) -> None:
        """ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶"""
        try:
            history_data = []
            for turn in self.conversation_history:
                turn_dict = {
                    "user_query": turn.user_query,
                    "ai_response": turn.ai_response,
                    "timestamp": turn.timestamp.isoformat(),
                    "session_id": turn.session_id,
                    "metadata": turn.metadata,
                    "retrieved_docs": turn.retrieved_docs,
                    "context_summary": turn.context_summary,
                    "keywords": turn.keywords
                }
                history_data.append(turn_dict)

            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")

    def _load_history(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.memory_file):
                with open(self.memory_file, "r", encoding="utf-8") as f:
                    history_data = json.load(f)

                for turn_dict in history_data[-self.max_history:]:  # åªåŠ è½½æœ€è¿‘çš„è®°å½•
                    turn = ConversationTurn(
                        user_query=turn_dict["user_query"],
                        ai_response=turn_dict["ai_response"],
                        timestamp=datetime.fromisoformat(turn_dict["timestamp"]),
                        session_id=turn_dict["session_id"],
                        metadata=turn_dict.get("metadata", {}),
                        retrieved_docs=turn_dict.get("retrieved_docs", []),
                        context_summary=turn_dict.get("context_summary", ""),
                        keywords=turn_dict.get("keywords", [])
                    )
                    self.conversation_history.append(turn)

        except Exception as e:
            print(f"åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")

    def clear_history(self) -> None:
        """æ¸…ç©ºå†å²è®°å½•"""
        self.conversation_history.clear()
        self.current_session_id = self._generate_session_id()

        # åˆ é™¤å†å²æ–‡ä»¶
        if os.path.exists(self.memory_file):
            os.remove(self.memory_file)

    def get_conversation_stats(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        if not self.conversation_history:
            return {
                "total_conversations": 0,
                "current_session_length": 0,
                "most_discussed_topics": [],
                "avg_response_length": 0
            }

        # ç»Ÿè®¡ä¿¡æ¯
        total_conversations = len(self.conversation_history)
        current_session_conversations = len([
            turn for turn in self.conversation_history
            if turn.session_id == self.current_session_id
        ])

        # ç»Ÿè®¡è¯é¢˜
        all_keywords = []
        for turn in self.conversation_history:
            all_keywords.extend(turn.keywords)

        topic_counts = {}
        for keyword in all_keywords:
            topic_counts[keyword] = topic_counts.get(keyword, 0) + 1

        most_discussed = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:5]

        # å¹³å‡å›ç­”é•¿åº¦
        avg_response_length = sum(len(turn.ai_response) for turn in self.conversation_history) / len(self.conversation_history)

        return {
            "total_conversations": total_conversations,
            "current_session_length": current_session_conversations,
            "most_discussed_topics": [{"topic": topic, "count": count} for topic, count in most_discussed],
            "avg_response_length": round(avg_response_length, 1)
        }

    def export_conversation(self, format: str = "json") -> str:
        """å¯¼å‡ºå¯¹è¯å†å²"""
        if format == "json":
            return self._export_as_json()
        elif format == "txt":
            return self._export_as_text()
        else:
            raise ValueError("Unsupported export format")

    def _export_as_json(self) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        export_data = []
        for turn in self.conversation_history:
            export_data.append({
                "timestamp": turn.timestamp.isoformat(),
                "user": turn.user_query,
                "assistant": turn.ai_response,
                "session": turn.session_id,
                "keywords": turn.keywords
            })

        return json.dumps(export_data, ensure_ascii=False, indent=2)

    def _export_as_text(self) -> str:
        """å¯¼å‡ºä¸ºæ–‡æœ¬æ ¼å¼"""
        lines = ["=" * 60, "å¯¹è¯å†å²å¯¼å‡º", "=" * 60]

        for i, turn in enumerate(self.conversation_history, 1):
            lines.append(f"\n[{i}] {turn.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
            lines.append(f"ç”¨æˆ·: {turn.user_query}")
            lines.append(f"åŠ©æ‰‹: {turn.ai_response}")
            if turn.keywords:
                lines.append(f"å…³é”®è¯: {', '.join(turn.keywords)}")
            lines.append("-" * 40)

        return "\n".join(lines)


# ç®€åŒ–çš„LangChainå…¼å®¹ç±»ï¼ˆç§»é™¤äº†ä¾èµ–ï¼‰
# class LangChainChatMemory:
#     """å…¼å®¹LangChainçš„èŠå¤©è®°å¿†ç±»"""
#     pass


# å…¨å±€è®°å¿†å®ä¾‹
_global_memory = None


def get_conversation_memory() -> ConversationMemory:
    """è·å–å…¨å±€å¯¹è¯è®°å¿†å®ä¾‹"""
    global _global_memory
    if _global_memory is None:
        _global_memory = ConversationMemory()
    return _global_memory


def reset_conversation_memory():
    """é‡ç½®å…¨å±€å¯¹è¯è®°å¿†"""
    global _global_memory
    if _global_memory:
        _global_memory.clear_history()
    _global_memory = ConversationMemory()


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # æµ‹è¯•å¯¹è¯è®°å¿†åŠŸèƒ½
    print("ğŸ§  æµ‹è¯•å¯¹è¯è®°å¿†åŠŸèƒ½")
    print("=" * 50)

    memory = ConversationMemory(max_history=5)

    # æ¨¡æ‹Ÿå‡ è½®å¯¹è¯
    conversations = [
        ("ç°åœ¨å®Œæˆæ—¶çš„ç”¨æ³•æ˜¯ä»€ä¹ˆï¼Ÿ", "ç°åœ¨å®Œæˆæ—¶ç”¨æ¥è¡¨ç¤ºä»è¿‡å»å¼€å§‹æŒç»­åˆ°ç°åœ¨çš„åŠ¨ä½œ..."),
        ("èƒ½ç»™ä¸€äº›ä¾‹å­å—ï¼Ÿ", "å½“ç„¶å¯ä»¥ã€‚ä¾‹å¦‚ï¼š'I have lived here for 10 years'..."),
        ("é‚£ä¹ˆè¿‡å»æ—¶å’Œç°åœ¨å®Œæˆæ—¶çš„åŒºåˆ«ï¼Ÿ", "è¿‡å»æ—¶è¡¨ç¤ºç‰¹å®šæ—¶é—´å‘ç”Ÿçš„åŠ¨ä½œï¼Œè€Œç°åœ¨å®Œæˆæ—¶å¼ºè°ƒä¸ç°åœ¨çš„è”ç³»...")
    ]

    for user_query, ai_response in conversations:
        memory.add_conversation_turn(user_query, ai_response)
        print(f"ç”¨æˆ·: {user_query}")
        print(f"åŠ©æ‰‹: {ai_response[:50]}...")
        print()

    # æµ‹è¯•ä¸Šä¸‹æ–‡è·å–
    current_query = "èƒ½å†è¯¦ç»†è§£é‡Šä¸€ä¸‹å—ï¼Ÿ"
    context = memory.get_context_for_query(current_query)
    print("ğŸ“ ä¸Šä¸‹æ–‡ä¿¡æ¯:")
    print(context)
    print()

    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    stats = memory.get_conversation_stats()
    print("ğŸ“Š å¯¹è¯ç»Ÿè®¡:")
    print(json.dumps(stats, ensure_ascii=False, indent=2))

    print("\nâœ… å¯¹è¯è®°å¿†åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")